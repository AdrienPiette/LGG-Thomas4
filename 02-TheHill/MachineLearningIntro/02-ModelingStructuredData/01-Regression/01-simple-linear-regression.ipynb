{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "Linear regression is the simplest model of machine learning. \n",
    "The purpose of regression is to explain and predict a variable $y$ using a variable $x$ (or several variables $x_{(1)}$, ...,$x_{(n)}$ ).  \n",
    "\n",
    "The variable $y$ is called the **target** (dependent variable) , and the variables $x$ are called  **feature(s)** (independent variables).\n",
    "\n",
    "By convention, we call the number of rows $m$. The number of features is represented by $n$.\n",
    "\n",
    "In this example, $m=7$ and $n=3$.\n",
    "\n",
    "**Note**: In this notebook, every time we will talk about programming variables, we will format the names like `this`. For mathematical variables and functions, we'll be formatting them like $this$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image dataset](./assets/example_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the problem\n",
    "In this chapter, we will analyze simple linear regression on an example. This presentation will allow us to explain linear regression in a simple case in order to understand the stakes of this method, the problems posed and the answers brought.\n",
    "\n",
    "Let's take this dataset which contains data on an employee's salary based on his years of experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>39343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "      <td>46205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>37731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>43525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "      <td>39891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.9</td>\n",
       "      <td>56642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>60150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.2</td>\n",
       "      <td>54445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.2</td>\n",
       "      <td>64445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.7</td>\n",
       "      <td>57189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.9</td>\n",
       "      <td>63218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>55794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>56957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.1</td>\n",
       "      <td>57081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.5</td>\n",
       "      <td>61111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.9</td>\n",
       "      <td>67938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.1</td>\n",
       "      <td>66029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.3</td>\n",
       "      <td>83088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.9</td>\n",
       "      <td>81363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.0</td>\n",
       "      <td>93940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.8</td>\n",
       "      <td>91738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.1</td>\n",
       "      <td>98273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.9</td>\n",
       "      <td>101302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.2</td>\n",
       "      <td>113812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.7</td>\n",
       "      <td>109431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.0</td>\n",
       "      <td>105582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9.5</td>\n",
       "      <td>116969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.6</td>\n",
       "      <td>112635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.3</td>\n",
       "      <td>122391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.5</td>\n",
       "      <td>121872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YearsExperience  Salary\n",
       "0               1.1   39343\n",
       "1               1.3   46205\n",
       "2               1.5   37731\n",
       "3               2.0   43525\n",
       "4               2.2   39891\n",
       "5               2.9   56642\n",
       "6               3.0   60150\n",
       "7               3.2   54445\n",
       "8               3.2   64445\n",
       "9               3.7   57189\n",
       "10              3.9   63218\n",
       "11              4.0   55794\n",
       "12              4.0   56957\n",
       "13              4.1   57081\n",
       "14              4.5   61111\n",
       "15              4.9   67938\n",
       "16              5.1   66029\n",
       "17              5.3   83088\n",
       "18              5.9   81363\n",
       "19              6.0   93940\n",
       "20              6.8   91738\n",
       "21              7.1   98273\n",
       "22              7.9  101302\n",
       "23              8.2  113812\n",
       "24              8.7  109431\n",
       "25              9.0  105582\n",
       "26              9.5  116969\n",
       "27              9.6  112635\n",
       "28             10.3  122391\n",
       "29             10.5  121872"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"./data/salary_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>39343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "      <td>46205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>37731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>43525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "      <td>39891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YearsExperience  Salary\n",
       "0              1.1   39343\n",
       "1              1.3   46205\n",
       "2              1.5   37731\n",
       "3              2.0   43525\n",
       "4              2.2   39891"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Find the values of $m$ and $n$ of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "\n",
    "# m = 30\n",
    "# n = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Goals\n",
    "We want to know whether, in general, years of experience have an influence on the wage and in what form this influence can be expressed. The goal is to better explain how wages vary with years of experience and possibly to predict wages based on years of experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Variables studied\n",
    "In this example, we are going to do a simple regression and we will therefore define two variables.\n",
    "- The variable `y` is the variable that must be regressed. The target to be predicted.\n",
    "\n",
    "- The variable `X` which will be the explanatory variable. The feature.\n",
    "\n",
    "The unofficial convention is to have uppercase `X` because it will usually be a 2D array (multiple features). However it's not the case here. `y` is lower case because it's just a 1D vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**  Create the `X` and `y` variables and define which column will be the target and which column will be the feature.  \n",
    "Variables `X` and `y` be must of type `numpy.ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.1  1.3  1.5  2.   2.2  2.9  3.   3.2  3.2  3.7  3.9  4.   4.   4.1\n",
      "  4.5  4.9  5.1  5.3  5.9  6.   6.8  7.1  7.9  8.2  8.7  9.   9.5  9.6\n",
      " 10.3 10.5] [[ 1.1]\n",
      " [ 1.3]\n",
      " [ 1.5]\n",
      " [ 2. ]\n",
      " [ 2.2]\n",
      " [ 2.9]\n",
      " [ 3. ]\n",
      " [ 3.2]\n",
      " [ 3.2]\n",
      " [ 3.7]\n",
      " [ 3.9]\n",
      " [ 4. ]\n",
      " [ 4. ]\n",
      " [ 4.1]\n",
      " [ 4.5]\n",
      " [ 4.9]\n",
      " [ 5.1]\n",
      " [ 5.3]\n",
      " [ 5.9]\n",
      " [ 6. ]\n",
      " [ 6.8]\n",
      " [ 7.1]\n",
      " [ 7.9]\n",
      " [ 8.2]\n",
      " [ 8.7]\n",
      " [ 9. ]\n",
      " [ 9.5]\n",
      " [ 9.6]\n",
      " [10.3]\n",
      " [10.5]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.array (df ['YearsExperience'])\n",
    "y = np.array (df.drop('Salary', axis=1))\n",
    "\n",
    "print(X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Relationship between variables\n",
    "Now it is a question of finding the type of relationship between the two variables.\n",
    "\n",
    "To do so, we will display in a scatter plot (randomly generated) variables that may or may not have any link between each other. Let's see what kind of relation we can obtain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No correlation**  \n",
    "\n",
    "Very rounded scatter plot, there is no apparent relationship.\n",
    "\n",
    "![](./assets/scatter_plot_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Positive linear correlation**\n",
    "  \n",
    "Very stretched scatter plot. The cloud has a very marked linear shape. There is a tendency for the two variables to vary in the same direction. The observed correlation is positive.\n",
    "\n",
    "![](./assets/scatter_plot_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Negative linear correlation**\n",
    "  \n",
    "The scatterplot is moderately stretched (linear form but less marked), from top left to bottom right: one observes on the sample a tendency of the variables to vary in opposite directions, the observed correlation is negative.\n",
    "\n",
    "![](./assets/scatter_plot_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perfect non-linear correlation**\n",
    "  \n",
    "The points are on a non-linear (parabolic) curve. The correlation observed is perfect, however it's non-linear. There is no monotonicity: the curve is first decreasing and then increasing.\n",
    "\n",
    "![](./assets/scatter_plot_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize our dataset on a scatter plot:\n",
    "\n",
    "**Exercise:** Create a scatter plot with matplotlib and the `X` and `y` data.  \n",
    "Add the label salary for the y-axis and number of years of experience for the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>YearsExperience</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary</th>\n",
       "      <td>0.978242</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 YearsExperience    Salary\n",
       "YearsExperience         1.000000  0.978242\n",
       "Salary                  0.978242  1.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "\n",
    "sns.scatterplot(data=df, x='Salary',y='YearsExperience')\n",
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the stretched and increasing shape of the scatter plot suggesting a linear-type positive correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the correlation rate between the variables. \n",
    "\n",
    "**Exercise:** Display the correlation rate between the two variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train-test split procedure is used to estimate the performance of machine learning algorithms when they are used to make predictions on data not used to train the model.\n",
    "\n",
    "It is a fast and easy procedure to perform, the results of which allow you to compare the performance of machine learning algorithms for your predictive modeling problem.\n",
    "\n",
    "Generally, the training dataset contains 80% of the whole dataset. The remaining 20% is for the test dataset.\n",
    "\n",
    "**Exercise:** Import `train_test_split` from `sklearn` and split the dataset and create the variables `X_train`, `X_test`, `y_train`, `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = np.array (df ['YearsExperience'])\n",
    "y = np.array (df.drop('Salary', axis=1))\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=42)\n",
    "X_train = np.array(X_train).reshape(-1,1)\n",
    "X_train = np.array(X_test).reshape (-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Load and fit the model\n",
    "\n",
    "We could see that the Linear Model could help us make good generalizations about our dataset. However, our model has to train several times on our training set. It is therefore an iterative algorithm. And at each iteration, the algorithm will calculate the error rate of the mean of the trained data set. The algorithm will then try to regress this error rate until it is as small as possible. \n",
    "\n",
    "But we are lucky because the sklearn library already has a ready-made linear model that minimizes this error rate. \n",
    "\n",
    "**Exercise:** \n",
    "1. Import `LinearRegression` from sklearn.\n",
    "2. Create a `regressor` variable and instantiate your `LinearRegression` class.\n",
    "2. Train your model with `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6, 24]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_base.py:609\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    605\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    607\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 609\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1320\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1320\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6, 24]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, your model is trained.   \n",
    "But let's check if our model is efficient. To do this we can display the score of our model. That is to say the number of correct predictions that our model was able to make."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Display the score of your model with `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you have a score above 90%? That's not bad! But let's now check if our model can make generalizations about data it has never seen before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test your model\n",
    "The `X_test` and `y_test` sets were previously created. Now it is time to use them. \n",
    "\n",
    "**Exercise:** Use the `predict` method of your model on your test dataset (`X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Display the score of your model with `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's your score? Is it higher than 90%? Awesome!\n",
    "\n",
    "To make it more meaningful, let's visualize the training and testing of your model.  \n",
    "\n",
    "**Exercise:** \n",
    "1. Plot `regressor.predict(X_train)`\n",
    "2. Plot the training set on top of it\n",
    "3. Add the title \"Salary VS Experience (Training set)\"\n",
    "4. Add the label \"Years of Experience\" on the x-axis and \"Salary\" on the y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected result should look like this:\n",
    "\n",
    "![train_plot](./assets/trainplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Do the same with `X_test`!  \n",
    "1. Plot `regressor.predict(X_test)`\n",
    "2. Plot the testing set on top of it.\n",
    "3. Add the title \"Salary VS Experience (Test set)\"\n",
    "4. Add the label \"Years of Experience\" on the x-axis and \"Salary\" on the y-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected result should look like this:\n",
    "\n",
    "![testplot.png](./assets/testplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Have fun testing your model by entering new data. To give you an example, according to my model, when I have 210 years of experience, I will earn a salary of 1,982,420 / year. I am looking forward to reaching that many years of experience... 😎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations to you! You have just created your first machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "![bravo](./assets/bravo.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
